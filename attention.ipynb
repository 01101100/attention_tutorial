{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "o43HsYMod3xO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.utils.data\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from random import randint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iDdQn4P6d3xl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "319a0fbf-650a-4253-eba8-20c14a3a790e"
      },
      "cell_type": "code",
      "source": [
        "! curl --silent -L -o data.zip \"https://drive.google.com/uc?export=download&id=1d6eUqRstk7NIpyASzbuIsDvBdHEwfU0g\"\n",
        "! unzip -q data.zip\n",
        "! ls data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data.csv  human_vocab.json  machine_vocab.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "17yzXiMWd3xp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e7f09b4d-4b42-4129-89c4-92ce8fcb30ef"
      },
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "    df = pd.read_csv(path, header=None)\n",
        "    X = df[0].values\n",
        "    y = df[1].values\n",
        "    x_tok = Tokenizer(char_level=True, filters='')\n",
        "    x_tok.fit_on_texts(X)\n",
        "    y_tok = Tokenizer(char_level=True, filters='')\n",
        "    y_tok.fit_on_texts(y)\n",
        "    \n",
        "    X = x_tok.texts_to_sequences(X)\n",
        "    y = y_tok.texts_to_sequences(y)\n",
        "    \n",
        "    X = pad_sequences(X)\n",
        "    y = np.asarray(y)\n",
        "    \n",
        "    return X, y, x_tok.word_index, y_tok.word_index\n",
        "\n",
        "X, y, x_wid, y_wid= load_data('data/data.csv')\n",
        "x_id2w = dict(zip(x_wid.values(), x_wid.keys()))\n",
        "y_id2w = dict(zip(y_wid.values(), y_wid.keys()))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "print('train size: {} - test size: {}'.format(len(X_train), len(X_test)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train size: 18750 - test size: 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VFK0Qetokq-S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fy7StSyzd3xz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a5b23f7a-e2a5-4eb0-ea5b-f59961fb130f"
      },
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "learning_rate = 0.001\n",
        "decoder_learning_ratio = 0.1\n",
        "\n",
        "# plus 1 is padding token\n",
        "input_size = len(x_wid) + 1\n",
        "# plus 2 is sos and eos token\n",
        "output_size = len(y_wid) + 2\n",
        "sos_idx = len(y_wid) \n",
        "eos_idx = len(y_wid) + 1\n",
        "\n",
        "max_length = y.shape[1]\n",
        "print(\"input vocab: {} - output vocab: {} - length of target: {}\".format(input_size, output_size, max_length))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input vocab: 35 - output vocab: 13 - length of target: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2LksDULqd3x3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decoder_sentence(idxs, vocab):\n",
        "    text = ''.join([vocab[w] for w in idxs if (w > 0) and (w in vocab)])\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yVx1T2LJd3x6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        # input: SxB        \n",
        "        embedded = self.embedding(input)\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden # SxBxH, 1xBxH              \n",
        "\n",
        "class Attn(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(Attn ,self).__init__()\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # encoder_outputs: TxBxH\n",
        "        # hidden: SxBxH\n",
        "        encoder_outputs = torch.transpose(encoder_outputs, 0, 1) #BxTxH\n",
        "        hidden = torch.transpose(torch.transpose(hidden, 0, 1), 1, 2) # BxHxS\n",
        "        energies = torch.bmm(encoder_outputs, hidden) # BxTxS\n",
        "        energies = torch.transpose(energies, 1, 2) # BxSxT\n",
        "        attn_weights = F.softmax(energies, dim=-1) #BxSxT\n",
        "        \n",
        "        output = torch.bmm(attn_weights, encoder_outputs) # BxSxH\n",
        "        output = torch.transpose(output, 0, 1) # SxBxH\n",
        "        attn_weights = torch.transpose(attn_weights, 0, 1) #SxBxT\n",
        "        \n",
        "        return output, attn_weights\n",
        "    \n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_size, hidden_size, dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attn = Attn(hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.concat = nn.Linear(self.hidden_size*2, hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        # input: SxB\n",
        "        # encoder_outputs: BxSxH\n",
        "        # hidden: 1xBxH\n",
        "        embedded = self.embedding(input) # 1xBxH\n",
        "        embedded = self.dropout(embedded)\n",
        "        rnn_output, hidden = self.gru(embedded, hidden)  #SxBxH, 1xBxH\n",
        "        context, attn_weights = self.attn(rnn_output, encoder_outputs) # SxBxH\n",
        "        concat_input = torch.cat((rnn_output, context), -1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input)) #SxBxH\n",
        "        \n",
        "        output = self.out(concat_output) # SxBxoutput_size\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ArLtO8rsd3yA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder = Encoder(input_size, hidden_size)\n",
        "decoder = Decoder(output_size, hidden_size, 0.1)\n",
        "\n",
        "# Initialize optimizers and criterion\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "input_encoder = torch.randint(1, input_size, (34, 6), dtype=torch.long)\n",
        "encoder_outputs, hidden = encoder(input_encoder)\n",
        "input_decoder = torch.randint(1, output_size, (10, 6), dtype=torch.long)\n",
        "output, hidden, attn_weights = decoder(input_decoder, hidden, encoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TnARQv5td3yG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forward_and_compute_loss(inputs, targets, encoder, decoder, criterion):\n",
        "    batch_size = inputs.size()[1]\n",
        "    \n",
        "    sos = Variable(torch.ones((1, batch_size), dtype=torch.long)*sos_idx)\n",
        "    eos = Variable(torch.ones((1, batch_size), dtype=torch.long)*eos_idx)\n",
        "    \n",
        "    decoder_inputs = torch.cat((sos, targets), dim=0)\n",
        "    decoder_targets = torch.cat((targets, eos), dim=0)\n",
        "    \n",
        "    encoder_outputs, encoder_hidden = encoder(inputs)\n",
        "    output, hidden, attn_weights = decoder(decoder_inputs, encoder_hidden, encoder_outputs)\n",
        "    \n",
        "    output = torch.transpose(torch.transpose(output, 0, 1), 1, 2) # BxCxS\n",
        "    decoder_targets = torch.transpose(decoder_targets, 0, 1)\n",
        "    loss = criterion(output, decoder_targets)\n",
        "    \n",
        "    return loss, output\n",
        "\n",
        "def train(inputs, targets,  encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    \n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    \n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "    \n",
        "    train_loss, output = forward_and_compute_loss(inputs, targets,encoder, decoder,criterion)    \n",
        "    \n",
        "    train_loss.backward()\n",
        "    \n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "            \n",
        "    return train_loss.item()\n",
        "\n",
        "def evaluate(inputs, targets, encoder, decoder, criterion):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    eval_loss, output = forward_and_compute_loss(*eval_data, encoder, decoder,criterion)\n",
        "    output = torch.transpose(output, 1, 2)\n",
        "    pred_idx = torch.argmax(output, dim=-1).squeeze(-1)\n",
        "    pred_idx = pred_idx.data.cpu().numpy()\n",
        "    \n",
        "    return eval_loss.item(), pred_idx\n",
        "\n",
        "def predict(inputs, encoder, decoder, target_length=max_length):    \n",
        "    batch_size = inputs.size()[1]\n",
        "    decoder_inputs = Variable(torch.ones((1, batch_size), dtype=torch.long)*sos_idx)\n",
        "    encoder_outputs, encoder_hidden = encoder(inputs)\n",
        "    hidden = encoder_hidden\n",
        "    preds = []\n",
        "    attn_weights = []\n",
        "    for i in range(target_length):\n",
        "        output, hidden, attn_weight = decoder(decoder_inputs, hidden, encoder_outputs)\n",
        "        output = output.squeeze(dim=0)\n",
        "        pred_idx = torch.argmax(output, dim=-1)\n",
        "        \n",
        "        decoder_inputs = Variable(torch.ones((1, batch_size), dtype=torch.long)*pred_idx)\n",
        "        preds.append(decoder_inputs)\n",
        "        attn_weights.append(attn_weight.detach())\n",
        "\n",
        "    preds = torch.cat(preds, dim=0)\n",
        "    preds = torch.transpose(preds, 0, 1)\n",
        "    attn_weights = torch.cat(attn_weights, dim=0)\n",
        "    attn_weights = torch.transpose(attn_weights, 0, 1)\n",
        "    return preds, attn_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cwNMda0Cd3yL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l-h8o5Rtd3yW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d1b40670-323a-4610-d1d6-48bb60401f63"
      },
      "cell_type": "code",
      "source": [
        "train(input_encoder, input_decoder, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.699028015136719"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "Fyfzas04d3yZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "outputId": "a266b3e0-0438-4af2-87e4-9c08847748a9"
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "encoder = Encoder(input_size, hidden_size)\n",
        "decoder = Decoder(output_size, hidden_size, 0.1)\n",
        "\n",
        "# Initialize optimizers and criterion\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "X_val = torch.tensor(X_test, dtype=torch.long)\n",
        "y_val = torch.tensor(y_test, dtype=torch.long)\n",
        "X_val = torch.transpose(X_val, 0, 1)\n",
        "y_val = torch.transpose(y_val, 0, 1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for idx in range(len(X_train)//batch_size):\n",
        "        X_train_batch = torch.tensor(X_train[batch_size*idx:batch_size*(idx+1)], dtype=torch.long)\n",
        "        y_train_batch = torch.tensor(y_train[batch_size*idx:batch_size*(idx+1)], dtype=torch.long)\n",
        "        \n",
        "        X_train_batch = torch.transpose(X_train_batch, 0, 1)\n",
        "        y_train_batch = torch.transpose(y_train_batch, 0, 1)\n",
        "        train_loss= train(X_train_batch, y_train_batch, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "    eval_loss, predict = evaluate(X_val, y_val, encoder, decoder, criterion)\n",
        "    \n",
        "    print('Epoch {} - train loss: {:.3f} - eval loss: {:.3f}'.format(epoch, train_loss, eval_loss))\n",
        "    print_idx = np.random.randint(0, len(predict), 3)\n",
        "    for i in print_idx:\n",
        "        x_val = decoder_sentence(X_val[:,i].numpy(), x_id2w)\n",
        "        y_predict = decoder_sentence(predict[i], y_id2w)\n",
        "        print(\" {:<35s}\\t{:>10}\".format(x_val, y_predict))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - train loss: 0.384 - eval loss: 0.360\n",
            " 26, thg 9 1975                     \t1975-09-26\n",
            " tháng 10 3 1998                    \t1998-00-03\n",
            " 17 tháng 5 1990                    \t1990-05-07\n",
            "Epoch 1 - train loss: 0.177 - eval loss: 0.164\n",
            " 19 thg 7, 1990                     \t1990-07-19\n",
            " thứ bảy, ngày 19 tháng 10 năm 2002 \t2002-01-19\n",
            " 10.08.74                           \t1974-08-10\n",
            "Epoch 2 - train loss: 0.075 - eval loss: 0.066\n",
            " 16 thg 9, 1996                     \t1996-09-16\n",
            " 3 03 17                            \t2017-03-33\n",
            " tháng 2 19 1974                    \t1974-02-19\n",
            "Epoch 3 - train loss: 0.047 - eval loss: 0.041\n",
            " 25 thg 6 1988                      \t1988-06-25\n",
            " 31 tháng 10, 1971                  \t1971-10-31\n",
            " 17.05.72                           \t1972-05-17\n",
            "Epoch 4 - train loss: 0.040 - eval loss: 0.037\n",
            " 9 thg 11 2004                      \t2004-11-09\n",
            " 4 tháng 4 2005                     \t2005-04-04\n",
            " 18 thg 1, 1976                     \t1976-11-18\n",
            "Epoch 5 - train loss: 0.035 - eval loss: 0.023\n",
            " 19 tháng 9 1981                    \t1981-09-19\n",
            " thứ hai, ngày 05 tháng 3 năm 2018  \t2018-03-05\n",
            " 19, thg 5 1988                     \t1988-05-19\n",
            "Epoch 6 - train loss: 0.017 - eval loss: 0.016\n",
            " ngày 06 tháng 03 năm 1988          \t1988-03-06\n",
            " 08/12/1978                         \t1978-12-08\n",
            " 1 tháng 7 2012                     \t2012-07-01\n",
            "Epoch 7 - train loss: 0.014 - eval loss: 0.010\n",
            " tháng 6 9, 1977                    \t1977-06-09\n",
            " 24 thg 11, 1990                    \t1990-11-24\n",
            " 09/08/1999                         \t1999-08-09\n",
            "Epoch 8 - train loss: 0.012 - eval loss: 0.012\n",
            " ngày 27 tháng 05 năm 2008          \t2008-05-27\n",
            " 24 tháng 1 1992                    \t1992-01-24\n",
            " 28 thg 11 1986                     \t1986-11-28\n",
            "Epoch 9 - train loss: 0.004 - eval loss: 0.009\n",
            " tháng 8 20 2002                    \t2002-08-20\n",
            " tháng 11 3 1976                    \t1976-11-03\n",
            " 9 thg 5 2016                       \t2016-05-09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NglXGh77d3yc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds, attn_weights = predict(X_val ,encoder, decoder, target_length=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vRMILrf6d3yj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_attention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticks(np.arange(len(input_sentence)))\n",
        "    ax.set_xticklabels(list(input_sentence), rotation=90)\n",
        "    ax.set_yticks(np.arange(len(output_words)))\n",
        "    ax.set_yticklabels(list(output_words))\n",
        "    ax.grid()\n",
        "    ax.set_xlabel('Input Sequence')\n",
        "    ax.set_ylabel('Output Sequence')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eFJvKjnOLL9W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "ad66743a-2531-44d7-a035-ec23efa270c5"
      },
      "cell_type": "code",
      "source": [
        "show_idx = randint(0, len(preds))\n",
        "text_x = decoder_sentence(X_val[:,show_idx].numpy(), x_id2w)\n",
        "text_y = decoder_sentence(preds[show_idx].numpy(), y_id2w)\n",
        "attn_weight = attn_weights[show_idx, :, -len(text_x):]\n",
        "show_attention(text_x, text_y, attn_weight)"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcgAAAE/CAYAAADCNlNLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wGiqzcwnjuXjAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "fy1-g7x4d3yq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nXsr_uanwbCD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZGdPKa19wd6b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3H3cKqsrDhLb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7gSiwI1vErr0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sh4Ilv5pE3MC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}