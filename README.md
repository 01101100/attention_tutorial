# Tìm hiểu và áp dụng cơ chế attention trong deep learning
## Giới Thiệu
Ở git này, mình cung cấp cho các bạn cài đặt chi tiết của cơ chế attention trong bài toàn seq2seq đã được đơn giản hóa. Đồng thời giải nghĩa kết quả tại mỗi thời điểm thông qua cơ chế này. Git này để phục vụ cho blog về attention mà mình đã viết, các bạn có thể đọc thêm tại [đây](https://pbcquoc.github.io/attention/) nhé.
## Tổng quan cơ chế attention trong deep learning

## Chi tiết cơ chế attention cho seq2seq
## Dataset
Để minh họa cơ chế attention, mình sử dụng tập dataset tự phát sinh như sau

| Input                            | Label         |
| ---------------------------------| ------------- |
| 12, thg 9 2010                   | 2010-09-12    |
| Thứ Tư, ngày 21 tháng 3 năm 1973 | 1973-03-21    |
| 31 thg 7, 1988                   | 1988-07-31    |

## Kết quả
## Any Problems?
Nếu có bất kì câu hỏi gì, các bạn có thể liên hệ mình thông qua địa chỉ pbcquoc@gmail.com nhé !.
(continued)
